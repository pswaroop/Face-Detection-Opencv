{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection OpenCV Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, There are 3 different models by which faces can be detected from images, video and also by using the Webcam for live detection of faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection using Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing OpenCV Library\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using haarcascade classifier and Hershey Duplex font \n",
    "FaceCascade = cv2.CascadeClassifier('cascade files/haarcascade_frontalface_alt.xml')\n",
    "font = cv2.FONT_HERSHEY_DUPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating video capture object but not capturing anything as the argument is zero\n",
    "cam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Capturing images of video from the webcam\n",
    "    visible, image = cam.read()\n",
    "    # Detecting faces from the images of video\n",
    "    faces = FaceCascade.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor = 1.1,\n",
    "        minNeighbors = 5,\n",
    "        minSize = (30,30),\n",
    "        flags = cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    # Iterating over detected faces and drawing a rectangle around them\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    # Printing the count of faces detected\n",
    "    cv2.putText(image,'No of Faces Detected : '+str(len(faces)),(160,24),font,1,thickness=1,color = (255,255,255))\n",
    "    # Output screen turns to GrayScale when no face is detected\n",
    "    if len(faces)==0:\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    # Showing the images of the video\n",
    "    cv2.imshow('Face Detector',image)\n",
    "    # For entering 'q' key to exit the window\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Releasing or destroying the video capture object\n",
    "cam.release()\n",
    "# Closing all output windows \n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing OpenCV Library\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the image from the 'Data' directory\n",
    "image = cv2.imread('Data/img1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Haarcascade classifier\n",
    "FaceCascade = cv2.CascadeClassifier('cascade files/haarcascade_frontalface_default.xml')\n",
    "# Detecting Faces from the image\n",
    "faces = FaceCascade.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor = 1.1,\n",
    "        minNeighbors = 6,\n",
    "        minSize = (30,30),\n",
    "        flags = cv2.CASCADE_SCALE_IMAGE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 faces!\n"
     ]
    }
   ],
   "source": [
    "# Printing the count of detected faces\n",
    "print(\"Found {0} faces!\".format(len(faces)))\n",
    "# Draw a rectangle around the detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the image with detected faces\n",
    "cv2.imshow(\"Faces found\", image)\n",
    "# For closing the window by clicking 'close' button or any key\n",
    "cv2.waitKey(0)\n",
    "# Destroying output window\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing OpenCV Library\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Haarcascade classifier\n",
    "FaceCascade = cv2.CascadeClassifier('cascade files/haarcascade_frontalface_alt.xml')\n",
    "# Capturing the video\n",
    "cam = cv2.VideoCapture('Data/face-demographics-walking.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Reading the images of the video\n",
    "    ret, img = cam.read()\n",
    "    # If the video ends, then the video capture object returns false to 'ret', resultantly output window closes automatically \n",
    "    if ret:\n",
    "        # Converting images of the video to GrayScale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Detecting faces from the video\n",
    "        faces = FaceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor = 1.2,\n",
    "            minNeighbors = 5,\n",
    "            minSize = (25,25),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        # Iterating over the detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Drawing a rectangle around detected faces\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        # Showing the video with detected faces    \n",
    "        cv2.imshow('img', img)\n",
    "        # closing the video by clicking 'q' key\n",
    "        if cv2.waitKey(10) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Releasing the video capture object\n",
    "cam.release()\n",
    "# Closing the output window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
